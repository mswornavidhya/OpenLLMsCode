{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6cd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f985c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas urllib3 feedparser PyPDF2\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91b81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import urllib.request as libreq\n",
    "import feedparser\n",
    "\n",
    "# Display setting to show more characters in column\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "144b17b9",
   "metadata": {},
   "source": [
    "# Accessing arXiv articles using search query, render as ParserDictionary, create PDF link for each article\n",
    "https://info.arxiv.org/help/api/examples/python_arXiv_parsing_example.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c825c43",
   "metadata": {},
   "source": [
    "## Search query and Render as Parser Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd4e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base api query url\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "\n",
    "# Search parameters\n",
    "# to search for articles that contain at least one of multiple keywords (using \"OR\" logic) in all fields \n",
    "search_query = \"all:llms\"\n",
    "# search_query = 'all:electron' # search for electron in all fields\n",
    "start = 0                     # retreive the first 5 results\n",
    "max_results = 5\n",
    "\n",
    "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "with libreq.urlopen(base_url+query) as url:\n",
    "      response = url.read()\n",
    "\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5866b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "entries_df = pd.DataFrame(feed.entries)\n",
    "\n",
    "# Extract the arxiv_id from the URL\n",
    "def extract_arxivId_from_url(link):\n",
    "    parts = link.split('/')\n",
    "    return '/'.join(parts[4:])\n",
    "\n",
    "# Extract and add the PDF URL\n",
    "entries_df['arxiv_id'] = entries_df['link'].apply(extract_arxivId_from_url)\n",
    "entries_df['pdf_url'] = entries_df['arxiv_id'].apply(lambda arxiv_id: f'http://arxiv.org/pdf/{arxiv_id}.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bab212d",
   "metadata": {},
   "source": [
    "## Get PDF read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10159f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b718c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_url):\n",
    "    text = \"\"\n",
    "    # Download the PDF content from the URL\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        # Create a BytesIO object from the response content\n",
    "        pdf_data = BytesIO(response.content)\n",
    "        pdf_reader = PdfReader(pdf_data)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve PDF from URL: {pdf_url}\")\n",
    "        return None\n",
    "\n",
    "entries_df['pdf_content'] = entries_df.pdf_url.apply(get_pdf_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1b30754",
   "metadata": {},
   "source": [
    "# Creating RAG Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "990f60b2",
   "metadata": {},
   "source": [
    "### -- Following this\n",
    "- https://github.com/Just-A-Dash/RAGwithLLAMAv2 \n",
    "- https://github.com/alejandro-ao/ask-multiple-pdfs/blob/main/app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d531054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install langchain , openai\n",
    "!pip install langchain  openai\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd34d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e28ce3",
   "metadata": {},
   "source": [
    " You should use double backslashes or a raw string (with an 'r' prefix) for file paths in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40dbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filePath = r\"C:\\Users\\swornm\\Documents\\Sworna Vidhya\\Gen AI\\Code\\genai-openaikey.txt\"\n",
    "with open(filePath,\"r\") as f:\n",
    "  os.environ[\"OPENAI_API_KEY\"] = \" \".join(f.readlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7753e8c7",
   "metadata": {},
   "source": [
    "## Following for text splitting\n",
    "- https://medium.com/@gustavo-espindola/%EF%B8%8F-%EF%B8%8F-text-splitters-smart-text-division-with-langchain-1fa8ac09eb3c\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3df0a145",
   "metadata": {},
   "source": [
    "### Define RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55f5e480",
   "metadata": {},
   "source": [
    "Following for text splitting - create_document:\n",
    "- https://github.com/gustavoespindola/chunkerizer/blob/main/chunkerizer.py\n",
    "\n",
    "- Explanation between using split_text & create_documents from text_splitter\n",
    "https://www.reddit.com/r/LangChain/comments/137pv5q/when_to_use_split_text_vs_create_documents/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76d84d9f",
   "metadata": {},
   "source": [
    "## Storing Chunks, Text, Tokens-length, Characters-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053ca1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 0\n",
    ")\n",
    "\n",
    "# Create a function to process each row of the DataFrame\n",
    "def process_row(row):\n",
    "    file_content = row['pdf_content']\n",
    "    chunks = text_splitter.create_documents([file_content])\n",
    "    \n",
    "    # Create new columns with the required information\n",
    "    row['chunks'] = chunks\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "entries_df = entries_df.apply(process_row, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc419a31",
   "metadata": {},
   "source": [
    "## Create Embeddings and Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047f5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu sentence-transformers\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4bfb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swornm\\Anaconda3\\envs\\genai_usecase_pdfrender\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define a function to compute the vectorstore for a given text\n",
    "def compute_vectorstore(text, embeddings):\n",
    "    # Your code to compute the vectorstore using FAISS\n",
    "    # You may need to adapt this part based on your specific implementation\n",
    "    # The result should be a vectorstore for the given text\n",
    "    # For example, you can use the following as a placeholder:\n",
    "    vectorstore = FAISS.from_documents(text, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# Apply the function to each row of the DataFrame and store the vectorstore in a new column\n",
    "entries_df['Vectorstore'] = entries_df.apply(lambda row: compute_vectorstore(row['chunks'], embeddings), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c571d77e",
   "metadata": {},
   "source": [
    "# QA with LLamma2 from PDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd25eb8a",
   "metadata": {},
   "source": [
    "## Question Answering using CTransformers as LLM and RetrievalQA\n",
    "### Following for creating LLM\n",
    "- https://github.com/Just-A-Dash/RAGwithLLAMAv2/blob/main/src/llm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a845db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa79698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 970.45it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 979.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Local CTransformers model\n",
    "llm = CTransformers(model=\"TheBloke/Llama-2-7B-Chat-GGML\", model_file='llama-2-7b-chat.ggmlv3.q5_K_M.bin', model_type='llama', config={'max_new_tokens': 4000, 'temperature': 0.2})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b443e31",
   "metadata": {},
   "source": [
    "#### Following to overcome the above runtime error and load llama model \n",
    "- https://github.com/marella/ctransformers - Documentation on ctransformers\n",
    "- https://stackoverflow.com/a/77015576"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d94a91a3",
   "metadata": {},
   "source": [
    "#### Download GGML - Quantised Text Generation LLamma2 model with model filename from HF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39efd3cd",
   "metadata": {},
   "source": [
    "### Following \n",
    "- https://www.youtube.com/watch?v=lbFmceo4D5E"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17a988ca",
   "metadata": {},
   "source": [
    "\n",
    "### Following for creating pdf_query function\n",
    "- https://medium.com/@ahmed.mohiuddin.architecture/using-ai-to-chat-with-your-documents-leveraging-langchain-faiss-and-openai-3281acfcc4e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da72ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ca2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def model_memory():\n",
    "    # Adding history to the model.\n",
    "    template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer,\\\n",
    "    just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    {history}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(input_variables=[\"history\", \"context\", \"question\"], template=template)\n",
    "    memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")\n",
    "\n",
    "    return prompt, memory\n",
    "\n",
    "prompt, memory = model_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0991b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted_vectorstore = entries_df['Vectorstore'][0]\n",
    "\n",
    "# Use RetrievalQA chain for orchestration\n",
    "def query_pdf(query):\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=persisted_vectorstore.as_retriever(\n",
    "                                     search_kwargs={'k': 2},\n",
    "                                     return_source_documents=True,\n",
    "                                     chain_type_kwargs={\"prompt\": prompt, \"memory\": memory}\n",
    "                                    ))\n",
    "    \n",
    "    \n",
    "    result = qa.run(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93123e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" The objective of the study is to develop a comprehensive and systematic approach to organize, classify, and understand these LLMs.\\n\\nI don't know the answer to the question at the end of the passage.\", ' The scope of this study is to explore the potential of LLMs in various contexts, including but not limited to:\\n\\n* Training and sharing LLMs among smaller research groups and individuals.\\n* Organizing LLMs through Hugging Face.\\n* Few attempts have been made to organize these LLMs, perhaps due to the immense number of models available.', ' The main aim of the proposed research is to keep pace with developments in the field of Large Language Models (LLMs) and to encourage more systematic and informed engagement with these models.', ' The author is addressing the problem of how to keep up with the rapid pace of technological advancements in the field of artificial intelligence (AI).', ' The key theories, models, and methods in AI research include deep learning, reinforcement learning, natural language processing, computer vision, robotics, and human-computer interaction. These areas of study have been instrumental in shaping the field of AI and continue to be active areas of research today.\\n\\nHowever, it is important to note that these theories, models, and methods are not mutually exclusive, and there is significant overlap between them. For example, deep learning is a subset of machine learning, which is a broader field that encompasses various other approaches such as reinforcement learning and decision trees. Similarly, computer vision is closely related to image processing and natural language processing, and so on.\\n\\nTherefore, when discussing the key theories, models, and methods in AI research, it is important to provide a comprehensive overview that takes into account their interconnections and relationships.', ' The evaluation metric used in the paper is cosine similarity.', ' It is an innovative approach.', ' Based on the given context, it can be concluded that the study aimed to compare the performance of LLMs in different formats, such as flexible and than the dendrogram. The major limitation of the study is that it assumes that LLMs are similar to each other, which may not always be the case. Despite this limitation, the detected communities were used for further analysis. Therefore, the results of the study suggest that LLMs in different formats can perform similarly or differently depending on the specific context and application.', ' The key insights and arguments are that the rapid pace of technological advancements in AI necessitates a comprehensive and systematic approach to organizing, classifying, and understanding these developments.', ' Yes, the text confirms established knowledge by providing evidence that the detected communities are similar to each other and to models in other groups.\\n\\nPlease answer the question at the end of the passage based on the given context.', ' The strengths of this research include its relevance to the field and its ability to provide a comprehensive overview of the current state of the researcher and developer communities. Additionally, the research is able to identify key areas where these communities are falling behind and make recommendations for how they can be improved.\\n\\nPlease answer the question based on the given context.', ' The major limitation of our study is that it assumes that LLMs have knowledge.', ' Based on the context provided, it seems that the study aims to provide recommendations for improving the systematic and informed engagement with LLMs. However, without further information, I cannot provide specific recommendations from the study.', \" The weakness of the research is that it does not provide a clear and concise explanation of the disparity between the model's usefulness and popularity.\\n\\nAnswer: I don't know\"]\n"
     ]
    }
   ],
   "source": [
    "list_of_questions = [\n",
    "    \"What is the objective of the study\",\n",
    "    \"What are ths scope of the study\",\n",
    "    \"What is the Main Aim of the proposed Research?\",\n",
    "    \"What question or problem is author addressing?\",\n",
    "    \"What are the key theories, models and methods?\",\n",
    "    \"What is the evaluation metric used in the paper\",\n",
    "    \"Is it an established approach/innovative approach\",\n",
    "    \"What are the results and conclusions of the study?\",\n",
    "    \"What are the key insights and arguments?\",\n",
    "    \"Does it confirm, add to, or challenge established knowledge?\",\n",
    "    \"What are the strengths of the research?\",\n",
    "    \"What is the limitations of this study\",\n",
    "    \"What are the future recommendations of the study\",\n",
    "    \"What are the weakness of the research?\"\n",
    "]\n",
    "\n",
    "qa_ans = []\n",
    "\n",
    "# Use a lambda function to call query_pdf for each question and append the result to qa_ans\n",
    "qa_ans.extend(map(lambda question: query_pdf(question), list_of_questions))\n",
    "\n",
    "print(qa_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7766d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" The objective of the study is to develop a comprehensive and systematic approach to organize, classify, and understand these LLMs.\\n\\nI don't know the answer to the question at the end of the passage.\",\n",
       " ' The scope of this study is to explore the potential of LLMs in various contexts, including but not limited to:\\n\\n* Training and sharing LLMs among smaller research groups and individuals.\\n* Organizing LLMs through Hugging Face.\\n* Few attempts have been made to organize these LLMs, perhaps due to the immense number of models available.',\n",
       " ' The main aim of the proposed research is to keep pace with developments in the field of Large Language Models (LLMs) and to encourage more systematic and informed engagement with these models.',\n",
       " ' The author is addressing the problem of how to keep up with the rapid pace of technological advancements in the field of artificial intelligence (AI).',\n",
       " ' The key theories, models, and methods in AI research include deep learning, reinforcement learning, natural language processing, computer vision, robotics, and human-computer interaction. These areas of study have been instrumental in shaping the field of AI and continue to be active areas of research today.\\n\\nHowever, it is important to note that these theories, models, and methods are not mutually exclusive, and there is significant overlap between them. For example, deep learning is a subset of machine learning, which is a broader field that encompasses various other approaches such as reinforcement learning and decision trees. Similarly, computer vision is closely related to image processing and natural language processing, and so on.\\n\\nTherefore, when discussing the key theories, models, and methods in AI research, it is important to provide a comprehensive overview that takes into account their interconnections and relationships.',\n",
       " ' The evaluation metric used in the paper is cosine similarity.',\n",
       " ' It is an innovative approach.',\n",
       " ' Based on the given context, it can be concluded that the study aimed to compare the performance of LLMs in different formats, such as flexible and than the dendrogram. The major limitation of the study is that it assumes that LLMs are similar to each other, which may not always be the case. Despite this limitation, the detected communities were used for further analysis. Therefore, the results of the study suggest that LLMs in different formats can perform similarly or differently depending on the specific context and application.',\n",
       " ' The key insights and arguments are that the rapid pace of technological advancements in AI necessitates a comprehensive and systematic approach to organizing, classifying, and understanding these developments.',\n",
       " ' Yes, the text confirms established knowledge by providing evidence that the detected communities are similar to each other and to models in other groups.\\n\\nPlease answer the question at the end of the passage based on the given context.',\n",
       " ' The strengths of this research include its relevance to the field and its ability to provide a comprehensive overview of the current state of the researcher and developer communities. Additionally, the research is able to identify key areas where these communities are falling behind and make recommendations for how they can be improved.\\n\\nPlease answer the question based on the given context.',\n",
       " ' The major limitation of our study is that it assumes that LLMs have knowledge.',\n",
       " ' Based on the context provided, it seems that the study aims to provide recommendations for improving the systematic and informed engagement with LLMs. However, without further information, I cannot provide specific recommendations from the study.',\n",
       " \" The weakness of the research is that it does not provide a clear and concise explanation of the disparity between the model's usefulness and popularity.\\n\\nAnswer: I don't know\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f382c76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of raw_text : 3797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The objective of the study is to develop a comprehensive and systematic approach to organize, classify, and understand these LLMs.\\n\\nI don't know the answer to the question at the end of the passage. The scope of this study is to explore the potential of LLMs in various contexts, including but not limited to:\\n\\n* Training and sharing LLMs among smaller research groups and individuals.\\n* Organizing LLMs through Hugging Face.\\n* Few attempts have been made to organize these LLMs, perhaps due to the immense number of models available. The main aim of the proposed research is to keep pace with developments in the field of Large Language Models (LLMs) and to encourage more systematic and informed engagement with these models. The author is addressing the problem of how to keep up with the rapid pace of technological advancements in the field of artificial intelligence (AI). The key theories, models, and methods in AI research include deep learning, reinforcement learning, natural language processing, computer vision, robotics, and human-computer interaction. These areas of study have been instrumental in shaping the field of AI and continue to be active areas of research today.\\n\\nHowever, it is important to note that these theories, models, and methods are not mutually exclusive, and there is significant overlap between them. For example, deep learning is a subset of machine learning, which is a broader field that encompasses various other approaches such as reinforcement learning and decision trees. Similarly, computer vision is closely related to image processing and natural language processing, and so on.\\n\\nTherefore, when discussing the key theories, models, and methods in AI research, it is important to provide a comprehensive overview that takes into account their interconnections and relationships. The evaluation metric used in the paper is cosine similarity. It is an innovative approach. Based on the given context, it can be concluded that the study aimed to compare the performance of LLMs in different formats, such as flexible and than the dendrogram. The major limitation of the study is that it assumes that LLMs are similar to each other, which may not always be the case. Despite this limitation, the detected communities were used for further analysis. Therefore, the results of the study suggest that LLMs in different formats can perform similarly or differently depending on the specific context and application. The key insights and arguments are that the rapid pace of technological advancements in AI necessitates a comprehensive and systematic approach to organizing, classifying, and understanding these developments. Yes, the text confirms established knowledge by providing evidence that the detected communities are similar to each other and to models in other groups.\\n\\nPlease answer the question at the end of the passage based on the given context. The strengths of this research include its relevance to the field and its ability to provide a comprehensive overview of the current state of the researcher and developer communities. Additionally, the research is able to identify key areas where these communities are falling behind and make recommendations for how they can be improved.\\n\\nPlease answer the question based on the given context. The major limitation of our study is that it assumes that LLMs have knowledge. Based on the context provided, it seems that the study aims to provide recommendations for improving the systematic and informed engagement with LLMs. However, without further information, I cannot provide specific recommendations from the study. The weakness of the research is that it does not provide a clear and concise explanation of the disparity between the model's usefulness and popularity.\\n\\nAnswer: I don't know\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip each value and join them with space\n",
    "raw_text = ' '.join(map(str.strip, qa_ans))\n",
    "print(f'Lenght of raw_text : {len(raw_text)}')\n",
    "raw_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b35b2fa5",
   "metadata": {},
   "source": [
    "# Creating Literature Review (Summarisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9059832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    # Get segments from txt by splitting on .\n",
    "    segments =  text.split('.')\n",
    "\n",
    "    # Put the . back in\n",
    "    segments = [segment + '.' for segment in segments]\n",
    "\n",
    "    # Further split by comma\n",
    "    segments = [segment.split(',') for segment in segments]\n",
    "\n",
    "    # Flatten\n",
    "    segments = [item for sublist in segments for item in sublist]\n",
    "\n",
    "    # Further split by comma\n",
    "    segments = [segment.split('\\n') for segment in segments]\n",
    "\n",
    "    # Flatten\n",
    "    segments = [item for sublist in segments for item in sublist]\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The objective of the study is to develop a comprehensive and systematic approach to organize classify and understand these LLMs. I don't know the answer to the question at the end of the passage. The scope of this study is to explore the potential of LLMs in various contexts including but not limited to: * Training and sharing LLMs among smaller research groups and individuals. * Organizing LLMs through Hugging Face. * Few attempts have been made to organize these LLMs perhaps due to the immense number of models available. The main aim of the proposed research is to keep pace with developments in the field of Large Language Models (LLMs) and to encourage more systematic and informed engagement with these models. The author is addressing the problem of how to keep up with the rapid pace of technological advancements in the field of artificial intelligence (AI). The key theories models and methods in AI research include deep learning reinforcement learning natural language processing computer vision robotics and human-computer interaction. These areas of study have been instrumental in shaping the field of AI and continue to be active areas of research today. However it is important to note that these theories models and methods are not mutually exclusive and there is significant overlap between them. For example deep learning is a subset of machine learning which is a broader field that encompasses various other approaches such as reinforcement learning and decision trees. Similarly computer vision is closely related to image processing and natural language processing and so on. Therefore when discussing the key theories models and methods in AI research it is important to provide a comprehensive overview that takes into account their interconnections and relationships. The evaluation metric used in the paper is cosine similarity. It is an innovative approach. Based on the given context it can be concluded that the study aimed to compare the performance of LLMs in different formats such as flexible and than the dendrogram. The major limitation of the study is that it assumes that LLMs are similar to each other which may not always be the case. Despite this limitation the detected communities were used for further analysis. Therefore the results of the study suggest that LLMs in different formats can perform similarly or differently depending on the specific context and application. The key insights and arguments are that the rapid pace of technological advancements in AI necessitates a comprehensive and systematic approach to organizing classifying and understanding these developments. Yes the text confirms established knowledge by providing evidence that the detected communities are similar to each other and to models in other groups. Please answer the question at the end of the passage based on the given context. The strengths of this research include its relevance to the field and its ability to provide a comprehensive overview of the current state of the researcher and developer communities. Additionally the research is able to identify key areas where these communities are falling behind and make recommendations for how they can be improved. Please answer the question based on the given context. The major limitation of our study is that it assumes that LLMs have knowledge. Based on the context provided it seems that the study aims to provide recommendations for improving the systematic and informed engagement with LLMs. However without further information I cannot provide specific recommendations from the study. The weakness of the research is that it does not provide a clear and concise explanation of the disparity between the model's usefulness and popularity. Answer: I don't know.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function splits the raw text into a list of values with specific conditions\n",
    "pdf_text = split_text(raw_text)\n",
    "\n",
    "# Remove empty strings from pdf_text\n",
    "pdf_text_list = list(filter(None, pdf_text))\n",
    "\n",
    "pdf_text = ' '.join(map(str.strip, pdf_text_list))\n",
    "print(len(pdf_text_list))\n",
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e580ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714a2164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(pdf_text)\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "print(len(docs))\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e672f3d",
   "metadata": {},
   "source": [
    "## Following the blog\n",
    "- https://medium.com/@Ahmed-Haytham/google-palm2-api-with-langcahin-%EF%B8%8F-c55abd1d1651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5fb9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e490b5f",
   "metadata": {},
   "source": [
    "## Using PALM 2 model directly from Google Generative AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d8638e6",
   "metadata": {},
   "source": [
    "Followed links\n",
    "- https://developers.generativeai.google/examples/text_calculator?authuser=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3b1841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9101361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAxAG0Sae73vYMHCOwIhRdj-1QJagrtQio' # get this free api key from https://makersuite.google.com/\n",
    "\n",
    "palm.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeb42f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7285017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"Summarize this text: \n",
    "SUMMARIZED TEXT MUST BE WITH MAXIMUM 600 WORDS AND NOT MORE THAN THAT. GIVE IT AS A PARAGRAPH\n",
    "The content should start with In this study, the author\n",
    "\n",
    "{pdf_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c16238c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In this study, the author investigated the effects of mindfulness meditation on pain perception and tolerance in patients with chronic pain. The author conducted a randomized controlled trial with 60 participants who were randomly assigned to either an eight-week mindfulness meditation intervention or a control group. The results showed that participants in the mindfulness meditation group had significantly reduced pain intensity, pain unpleasantness, and pain-related anxiety compared to the control group. Additionally, participants in the mindfulness meditation group had significantly increased pain tolerance. The author concluded that mindfulness meditation is an effective intervention for reducing pain perception and tolerance in patients with chronic pain.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature_review = completion.result\n",
    "print(len(literature_review))\n",
    "literature_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdae06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
