{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get this free api key from https://makersuite.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swornm\\Anaconda3\\envs\\genai_pe\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import google.generativeai as genai\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAxAG0Sae73vYMHCOwIhRdj-1QJagrtQio' # get this free api key from https://makersuite.google.com/\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "for mmodel in genai.list_models():\n",
    "    print(mmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in genai.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "text_model = models[0].name\n",
    "print(text_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Principles:\n",
    "## Principle 1 - Write clear and specific instructions:\n",
    "### Tactic 1 - Use delimeters like:\n",
    "            triple quotes\"\"\", triple backticks```, \n",
    "            triple dashes---,angle brackets<> \n",
    "### Tactic 2 - Ask for structured output like JSON, HTML,...\n",
    "\n",
    "### Tactic 3 - Check whether conditions are satisfied\n",
    "### Tactic 4: \"Few-shot\" prompting\n",
    "            give examples of how you want a problem to be solved\n",
    "            \n",
    "## Principle 2 - Give the model time to “think”\n",
    "### Tactic 1: Specify the steps required to complete a task\n",
    "### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(input_text):\n",
    "    completion = genai.generate_text(\n",
    "            model=text_model,\n",
    "            prompt=input_text,\n",
    "            temperature=0,\n",
    "            # The maximum length of the response\n",
    "            max_output_tokens=1024,\n",
    "        )\n",
    "    return completion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Principle 1, Tactic 1 - use delimeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(candidates=[...],\n",
       "           result=('In five years, I will be financially stable, physically fit, have a '\n",
       "                   'fulfilling career, and maintain close relationships with my friends and '\n",
       "                   'family.'),\n",
       "           filters=[],\n",
       "           safety_feedback=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In five years from now, I will have achieved financial freedom and stability. I will have a healthy and positive relationship with money, and my spending habits will reflect that. I will have a substantial amount of savings and will not need to rely on credit cards or live paycheck to paycheck. I will have a clear understanding of my financial goals and how to achieve them, which will enable me to have more control over my financial future.\n",
    "Physically, I will have reached my full potential. I will have achieved my fitness goals, including a skillset of calisthenics movements such as Muscle-up, Handstand, L-Sit, Human-Flag, and Planche, as well as good mobility and functional strength. I will have a healthy diet that supports my physical goals, and I will feel great both mentally and physically. This physical fitness will give me the confidence and energy to pursue new challenges and opportunities.\n",
    "In terms of work, I will have a fulfilling career that allows me to travel and explore new opportunities. I will feel valued and appreciated by my colleagues and superiors, and I will have enough time for breaks and to manage my workload effectively. My job will be something that I am passionate about and that allows me to make a positive impact in the world. This will give me a sense of purpose and fulfillment that I have been striving for.\n",
    "On the social front, I will maintain close relationships with my friends and family, both near and far. I will have a small circle of very close friends, as well as a slightly bigger circle full of nice and kind people surrounding me. I will feel a sense of belonging and community. These relationships will be a source of joy and support, and they will give me the strength and motivation to continue pursuing my goals and dreams.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by --- into a single sentence.\n",
    "---{text}---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In five years, I will be financially stable, physically fit, have a fulfilling career, and maintain close relationships with my friends and family.\n"
     ]
    }
   ],
   "source": [
    "print(response.result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Principle 1, Tactic 2 - Ask for structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"habbit\": \"Create a budget and track your spending\",\n",
      "    \"description\": \"This will help you to see where your money is going and make adjustments as needed.\",\n",
      "    \"priority\": \"High\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Automate your savings\",\n",
      "    \"description\": \"This will help you to save money without even thinking about it.\",\n",
      "    \"priority\": \"High\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Pay yourself first\",\n",
      "    \"description\": \"This means setting aside money for your savings before you pay any other bills.\",\n",
      "    \"priority\": \"High\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Reduce your expenses\",\n",
      "    \"description\": \"This will free up more money to put towards your savings or debt repayment.\",\n",
      "    \"priority\": \"Medium\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Increase your income\",\n",
      "    \"description\": \"This will help you to pay off your debt faster and reach financial freedom sooner.\",\n",
      "    \"priority\": \"Medium\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Invest your money\",\n",
      "    \"description\": \"This will help you to grow your wealth and reach your financial goals.\",\n",
      "    \"priority\": \"Low\"\n",
      "  },\n",
      "  {\n",
      "    \"habbit\": \"Get out of debt\",\n",
      "    \"description\": \"This is the ultimate goal of financial freedom.\",\n",
      "    \"priority\": \"Low\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Generate a list of Habbits to implement to get dept free and reach financial freedom.\n",
    "provide them in JSON format with the following keys:\n",
    "habbit,description,priority.'''\n",
    "response = get_completion(prompt)\n",
    "print(response.result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Principle 1, Tactic 3 - Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Put a tea bag in a cup.\n",
      "Step 3 - Pour the boiling water over the tea bag.\n",
      "Step 4 - Let the tea steep for a few minutes.\n",
      "Step 5 - Remove the tea bag.\n",
      "Step 6 - Add sugar or milk to taste.\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response.result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Principle 1, Tactic 4 - few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <grandparent>: The oak tree that stands tall and proud \\ \n",
      "in the midst of a storm is the same tree that \\ \n",
      "was once a sapling, bent and broken by the wind.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response.result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Principle 2, Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "# response = get_completion(prompt_1)\n",
    "# print(\"Completion for prompt 1:\")\n",
    "# print(response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87”\n",
    "- DEPTH 51 CM | 20.08”\n",
    "- HEIGHT 80 CM | 31.50”\n",
    "- SEAT HEIGHT 44 CM | 17.32”\n",
    "- SEAT DEPTH 41 CM | 16.14”\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(candidates=[...],\n",
      "           result=...,\n",
      "           filters=[],\n",
      "           safety_feedback=[])\n",
      "\n",
      "**Mid-Century Modern Swivel Chair**\n",
      "\n",
      "The mid-century modern swivel chair is a stylish and comfortable addition to any home or office. It features a sleek, minimalist design with a choice of shell colors and base finishes. The chair is available with or without armrests, and is made with high-quality materials that are built to last.\n",
      "\n",
      "**Features:**\n",
      "\n",
      "* Sleek, minimalist design\n",
      "* Choice of shell colors and base finishes\n",
      "* Available with or without armrests\n",
      "* Made with high-quality materials\n",
      "* Built to last\n",
      "\n",
      "**Dimensions:**\n",
      "\n",
      "* Width: 53 cm\n",
      "* Depth: 51 cm\n",
      "* Height: 80 cm\n",
      "* Seat height: 44 cm\n",
      "* Seat depth: 41 cm\n",
      "\n",
      "**Options:**\n",
      "\n",
      "* Soft or hard-floor caster options\n",
      "* Two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
      "* Armless or 8 position PU armrests\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* Shell: Cast Aluminum with modified nylon PA6/PA66 coating\n",
      "* Base: 5-wheel plastic coated aluminum base\n",
      "* Seat: HD36 foam\n",
      "\n",
      "**Country of Origin:**\n",
      "\n",
      "* Italy\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "print()\n",
    "print(response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<h2>Mid-Century Modern Swivel Chair</h2>\n",
      "<p>The Mid-Century Modern Swivel Chair is a stylish and comfortable chair that is perfect for any home or office. It features a sleek, mid-century modern design and is available in a variety of colors and finishes to suit your needs. The chair is made from high-quality materials and construction, and is built to last.</p>\n",
      "<p>The Mid-Century Modern Swivel Chair is available with or without armrests, and is also available in a variety of seat foam densities. The chair is also height adjustable, so you can find the perfect position for your comfort.</p>\n",
      "<p>The Mid-Century Modern Swivel Chair is a great choice for anyone looking for a stylish and comfortable chair that is built to last.</p>\n",
      "<p>Product IDs: SWC-100, SWC-110</p>\n",
      "\n",
      "<h3>Product Dimensions</h3>\n",
      "<table>\n",
      "<tr>\n",
      "<th>Dimension</th>\n",
      "<th>Inches</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Width</td>\n",
      "<td>20.87</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Depth</td>\n",
      "<td>20.08</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Height</td>\n",
      "<td>31.50</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Seat Height</td>\n",
      "<td>17.32</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Seat Depth</td>\n",
      "<td>16.14</td>\n",
      "</tr>\n",
      "</table>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response.result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h2>Mid-Century Modern Swivel Chair</h2>\n",
    "<p>The Mid-Century Modern Swivel Chair is a stylish and comfortable chair that is perfect for any home or office. It features a sleek, mid-century modern design and is available in a variety of colors and finishes to suit your needs. The chair is made from high-quality materials and construction, and is built to last.</p>\n",
    "<p>The Mid-Century Modern Swivel Chair is available with or without armrests, and is also available in a variety of seat foam densities. The chair is also height adjustable, so you can find the perfect position for your comfort.</p>\n",
    "<p>The Mid-Century Modern Swivel Chair is a great choice for anyone looking for a stylish and comfortable chair that is built to last.</p>\n",
    "<p>Product IDs: SWC-100, SWC-110</p>\n",
    "\n",
    "<h3>Product Dimensions</h3>\n",
    "<table>\n",
    "<tr>\n",
    "<th>Dimension</th>\n",
    "<th>Inches</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Width</td>\n",
    "<td>20.87</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Depth</td>\n",
    "<td>20.08</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Height</td>\n",
    "<td>31.50</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Seat Height</td>\n",
    "<td>17.32</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Seat Depth</td>\n",
    "<td>16.14</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodel tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/llegomark/gemini-pro-chat/blob/main/chat.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Asad-94/Image-Description-Generation-Using-Google-Gemini-Pro-Model/blob/main/gemini_streamlit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': '**Summary:** Jack and Jill\\'s quest for water ends in a tumble down the hill, but their spirits remain high.\\n\\n**French Summary:** Jack et Jill partent chercher de l\\'eau au puits, mais tombent de la colline.\\n\\n**Names in French Summary:**\\n- Jack\\n- Jill\\n\\n**JSON Object:**\\n```\\n{\\n  \"french_summary\": \"Jack et Jill partent chercher de l\\'eau au puits, mais tombent de la colline.\",\\n  \"num_names\": 2\\n}\\n```'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "**Summary:** Jack and Jill's quest for water ends in a tumble down the hill, but their spirits remain high.\n",
      "\n",
      "**French Summary:** Jack et Jill partent chercher de l'eau au puits, mais tombent de la colline.\n",
      "\n",
      "**Names in French Summary:**\n",
      "- Jack\n",
      "- Jill\n",
      "\n",
      "**JSON Object:**\n",
      "```\n",
      "{\n",
      "  \"french_summary\": \"Jack et Jill partent chercher de l'eau au puits, mais tombent de la colline.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# generation_model = 'models/gemini-pro'\n",
    "\n",
    "generation_config = {\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"max_output_tokens\": 2048,\n",
    "    }\n",
    "\n",
    "safety_settings = {\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_NONE\",\n",
    "    }\n",
    "\n",
    "generation_model = genai.GenerativeModel(\n",
    "        'gemini-pro', generation_config=generation_config, safety_settings=safety_settings)\n",
    "response = generation_model.generate_content(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)\n",
    "print('\\n\\n')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Summary: Jack and Jill's quest for water from a hilltop well ends in a tumble, but their adventurous spirits remain strong.\n",
      "Translation: Jack et Jill partent chercher de l'eau dans un puits au sommet d'une colline, mais ils trébuchent et tombent, bien qu'ils soient légèrement blessés, ils rentrent chez eux réconfortés et continuent à explorer avec plaisir.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\n",
      "  \"french_summary\": \"Jack et Jill partent chercher de l'eau dans un puits au sommet d'une colline, mais ils trébuchent et tombent, bien qu'ils soient légèrement blessés, ils rentrent chez eux réconfortés et continuent à explorer avec plaisir.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in Italian summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = generation_model.generate_content(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principle 2, Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = generation_model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the student's solution is actually not correct.\n",
    "\n",
    "We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "```\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "no\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = generation_model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
